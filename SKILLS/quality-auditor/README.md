# Quality Auditor Skill

**Comprehensive quality auditing and evaluation against the highest industry standards**

---

## What This Skill Does

The **quality-auditor** skill evaluates tools, frameworks, systems, and codebases across **12 critical dimensions** with rigorous, evidence-based scoring.

### 12 Evaluation Dimensions

1. **Code Quality** - Structure, patterns, maintainability
2. **Architecture** - Design, scalability, modularity
3. **Documentation** - Completeness, clarity, accuracy
4. **Usability** - User experience, learning curve
5. **Performance** - Speed, efficiency, optimization
6. **Security** - Vulnerabilities, best practices
7. **Testing** - Coverage, quality, automation
8. **Maintainability** - Technical debt, refactorability
9. **Developer Experience** - Ease of use, tooling
10. **Accessibility** - ADHD-friendly, inclusive design
11. **CI/CD** - Automation, deployment
12. **Innovation** - Novelty, forward-thinking

---

## When to Use

Use this skill when you need to:

- ✅ **Audit your own tools** - Measure quality objectively
- ✅ **Evaluate third-party tools** - Make informed decisions
- ✅ **Conduct code reviews** - Comprehensive assessment
- ✅ **Benchmark against competitors** - See how you stack up
- ✅ **Identify improvements** - Get actionable recommendations
- ✅ **Validate quality claims** - Evidence-based verification
- ✅ **Prepare for production** - Pre-launch quality gate
- ✅ **Due diligence** - Investment or acquisition evaluation

---

## How It Works

### 3-Phase Process

**Phase 1: Discovery (10 min)**
- Read all documentation
- Examine codebase
- Test functionality
- Review supporting materials

**Phase 2: Evaluation (30-60 min)**
- Score each of 12 dimensions (1-10)
- Provide evidence for each score
- Identify strengths and weaknesses
- Compare against industry leaders

**Phase 3: Synthesis (20 min)**
- Create comprehensive report
- Prioritize improvements
- Provide actionable recommendations
- Benchmark against standards

**Total Time:** 60-90 minutes for thorough audit

---

## Scoring System

### 1-10 Scale

- **10** - Exceptional, industry-leading
- **9** - Excellent, significantly exceeds expectations
- **8** - Very good, above average
- **7** - Good, meets expectations
- **6** - Acceptable, minimum standards
- **5** - Below average, needs improvement
- **4** - Poor, major gaps
- **3** - Very poor, fundamental problems
- **2** - Critical issues
- **1** - Non-functional

### Overall Score

Weighted average of all dimensions:

```
Overall = (CodeQuality×10% + Architecture×10% + Documentation×10% +
          Usability×10% + Performance×8% + Security×10% + Testing×8% +
          Maintainability×8% + DevExp×10% + Accessibility×8% +
          CI/CD×5% + Innovation×3%)
```

---

## Usage Examples

### Example 1: Audit AI Dev Standards

```
You: "Use the quality-auditor skill to evaluate ai-dev-standards"

Claude:
"I'll conduct a comprehensive quality audit of ai-dev-standards
across all 12 dimensions.

Phase 1: Discovery...
[Reads documentation, examines code, tests functionality]

Phase 2: Evaluation...
[Scores each dimension with evidence]

Phase 3: Report...
[Generates comprehensive audit report]

# Quality Audit Report: ai-dev-standards

Overall Score: 8.7/10 - Excellent

[Full detailed report with scores, evidence, recommendations]"
```

---

### Example 2: Compare Tools

```
You: "Use the quality-auditor skill to compare Next.js vs Remix"

Claude:
"I'll audit both frameworks across all 12 dimensions and provide
a comparative analysis.

[Evaluates both]

# Comparative Quality Audit

| Dimension | Next.js | Remix | Winner |
|-----------|---------|-------|--------|
| Code Quality | 9/10 | 8/10 | Next.js |
| Documentation | 10/10 | 8/10 | Next.js |
| Performance | 8/10 | 9/10 | Remix |
...

[Full comparison with recommendations]"
```

---

### Example 3: Pre-Launch Quality Gate

```
You: "Use the quality-auditor skill to check if my app is production-ready"

Claude:
"I'll conduct a pre-launch audit focusing on critical dimensions
for production deployment.

# Pre-Launch Audit Report

**Production Readiness:** Not Yet ⚠️

**Blocking Issues:**
1. Security: 4/10 - Critical vulnerabilities found
2. Testing: 3/10 - Only 15% coverage
3. Performance: 5/10 - Page load >5s

**Must Fix Before Launch:**
[Prioritized list of critical issues]

**Timeline:** 2-3 weeks to address blocking issues"
```

---

## Report Structure

### Executive Summary
- Overall score + rating
- Top 3 strengths
- Top 3 weaknesses
- Final recommendation

### Detailed Scores
- Table with all 12 dimensions
- Individual scores + ratings
- Priority levels

### Dimension Analysis
- Each dimension examined
- Strengths + weaknesses
- Evidence cited
- Specific improvements

### Recommendations
- **Immediate** - Quick wins (1-2 weeks)
- **Short-term** - Important improvements (1-3 months)
- **Long-term** - Strategic changes (3-12 months)

### Comparative Analysis
- Industry leader comparison
- Benchmark against similar tools
- Unique differentiators

### Risk Assessment
- High/medium/low risk issues
- Impact analysis
- Mitigation strategies

---

## Industry Standards Referenced

The skill compares against established standards:

**Code Quality:**
- Clean Code (Robert Martin)
- Code Complete (Steve McConnell)
- SonarQube quality gates

**Security:**
- OWASP Top 10
- SANS Top 25
- CWE/SANS

**Accessibility:**
- WCAG 2.1 (AA/AAA)
- ADHD-friendly design principles

**Testing:**
- Test Pyramid (Mike Cohn)
- 80% minimum coverage

**Performance:**
- Core Web Vitals (Google)
- RAIL model

---

## Special Features

### ADHD-Friendly Evaluation

Additional scoring for ADHD-friendliness:

- **One-command simplicity** (10/10 = single command)
- **Automatic everything** (10/10 = zero manual steps)
- **Clear visual feedback** (progress indicators)
- **Minimal decisions** (sensible defaults)
- **Forgiving design** (easy undo, backups)
- **Low cognitive load** (simple mental model)

---

### Developer Experience Focus

Special attention to DX:

- Setup time (<5 min = excellent)
- Error message quality
- Debugging experience
- Documentation clarity
- Tool support

---

### Security-First

Comprehensive security audit:

- OWASP Top 10 check
- Dependency vulnerabilities
- Authentication/authorization review
- Data encryption assessment
- Secret management audit

---

## Benchmarking

### Industry Leaders Compared

**Code Quality:** Linux kernel, SQLite
**Documentation:** Stripe API, Tailwind CSS
**Usability:** Vercel, Netlify
**Developer Experience:** Next.js, Vite
**Performance:** Cloudflare Workers, Deno
**Security:** 1Password, Signal

---

## Key Principles

1. **Be Rigorous** - Compare against the best
2. **Be Objective** - Evidence-based only
3. **Be Constructive** - Actionable improvements
4. **Be Comprehensive** - All 12 dimensions
5. **Be Honest** - No inflated scores
6. **Be Specific** - Cite examples
7. **Be Actionable** - Implementable recommendations

---

## Limitations

**What this skill does NOT do:**

- ❌ Automated code analysis (use tools like SonarQube)
- ❌ Security penetration testing (use Burp Suite, OWASP ZAP)
- ❌ Performance load testing (use k6, JMeter)
- ❌ Replace human judgment (it augments, not replaces)

**This skill provides:**
- ✅ Comprehensive manual review
- ✅ Expert evaluation framework
- ✅ Structured assessment
- ✅ Actionable recommendations

---

## Tips for Best Results

### 1. Provide Context

```
❌ "Audit this tool"
✅ "Audit ai-dev-standards, focusing on developer experience and ADHD-friendliness"
```

### 2. Be Specific About Goals

```
❌ "Tell me if it's good"
✅ "Is this production-ready? What are the blocking issues?"
```

### 3. Request Comparisons

```
❌ "What's the score?"
✅ "How does this compare to industry leaders like Vercel?"
```

### 4. Ask for Priorities

```
❌ "List all issues"
✅ "What are the top 3 issues I should fix first?"
```

---

## Sample Report

See `EXAMPLES/quality-audit-report-sample.md` for a complete example report.

---

## Related Skills

- **performance-optimizer** - For detailed performance analysis
- **security-engineer** - For security-specific audits
- **testing-strategist** - For testing strategy
- **technical-writer** - For documentation improvement

---

## Frequently Asked Questions

### Q: How long does an audit take?

**A:** 60-90 minutes for a thorough audit of a medium-sized project. Larger projects may take 2-3 hours.

---

### Q: Can I audit my own project?

**A:** Yes! This is actually recommended. Regular self-audits help maintain quality.

---

### Q: How often should I audit?

**A:**
- **Pre-launch:** Always
- **Major releases:** Every time
- **Ongoing:** Quarterly or bi-annually
- **After incidents:** When issues occur

---

### Q: What if I disagree with a score?

**A:** Scores are evidence-based. If you disagree, provide counter-evidence and request re-evaluation of that dimension.

---

### Q: Can this audit closed-source tools?

**A:** Partially. Without code access, code quality and architecture scores are limited. Documentation, usability, and performance can still be evaluated.

---

### Q: Does a high score guarantee success?

**A:** No. Quality is necessary but not sufficient. Market fit, timing, and execution also matter. But high quality significantly increases chances of success.

---

## Changelog

### v1.0.0 (2025-10-22)
- Initial release
- 12-dimension evaluation framework
- Comprehensive scoring rubric
- Industry standards benchmarking
- ADHD-friendly special considerations

---

## Contributing

Found a missing evaluation criterion? Suggest improvements:

1. Identify the gap
2. Provide rationale
3. Suggest scoring rubric
4. Reference industry standards

---

## License

Part of ai-dev-standards. See main LICENSE file.

---

**Ready to evaluate?**

```
Use the quality-auditor skill to audit [tool-name]
```

**Or get specific:**

```
Use the quality-auditor skill to:
1. Audit ai-dev-standards
2. Focus on developer experience and ADHD-friendliness
3. Compare against industry leaders
4. Provide top 5 improvement priorities
```

---

**Built to measure excellence in software development** 📊
