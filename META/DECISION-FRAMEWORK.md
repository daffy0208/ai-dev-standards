# Decision Framework

## How to Make Architectural and Technical Decisions

This framework helps AI assistants make intelligent, documented choices when multiple options exist.

---

## Table of Contents

1. [Validation Before Building (CRITICAL)](#validation-before-building)
2. [Framework & Library Selection](#framework--library-selection)
3. [Architecture Patterns](#architecture-patterns)
4. [Platform & Stack Selection](#platform--stack-selection)
5. [Vector Database Selection](#vector-database-selection)
6. [Deployment Strategy](#deployment-strategy)
7. [Integration Approaches](#integration-approaches)
8. [Testing Strategy](#testing-strategy)
9. [Decision Process Template](#decision-process-template)

---

## Validation Before Building

### ğŸš¨ CRITICAL: Always Validate Before Building

**Before making ANY technical decisions about frameworks, databases, or architecture:**

**Ask these questions FIRST:**

1. **Has the problem been validated?**
   - Have we talked to users?
   - Is this a real problem people will pay to solve?
   - What's our evidence?

2. **Has the solution been validated?**
   - Have we tested simpler alternatives?
   - Do users actually want this feature?
   - Can we validate with a cheaper approach first?

3. **Is building the right next step?**
   - Or should we validate assumptions first?
   - Can we test with manual processes?
   - What's the cheapest way to learn?

### Validation-First Decision Tree

```
User requests technical implementation (RAG, multi-agent, etc.)
â”‚
â”œâ”€ Has problem been validated?
â”‚  â”œâ”€ No â†’ Use product-strategist skill FIRST
â”‚  â”‚      â†’ Validate problem (Mom Test interviews)
â”‚  â”‚      â†’ Return to this tree after validation
â”‚  â”‚
â”‚  â””â”€ Yes â†’ Continue to solution validation
â”‚
â”œâ”€ Has solution been validated?
â”‚  â”œâ”€ No â†’ Test cheaper alternatives FIRST
â”‚  â”‚      â”‚
â”‚  â”‚      â”œâ”€ RAG? Try: FAQ page â†’ Keyword search â†’ Semantic search
â”‚  â”‚      â”œâ”€ Multi-agent? Try: Single agent â†’ Manual coordination
â”‚  â”‚      â”œâ”€ Custom infra? Try: Managed platforms â†’ PaaS â†’ Self-hosted
â”‚  â”‚      â”‚
â”‚  â”‚      â†’ Return to this tree after testing
â”‚  â”‚
â”‚  â””â”€ Yes â†’ Continue to technical decisions
â”‚
â””â”€ Proceed with technical implementation
   â†’ Use appropriate decision framework sections below
```

### Cost Reality Checks

**Before implementing technical solutions, show users these alternatives:**

#### RAG Implementation
```
Before: RAG system (3-4 weeks, $200-500/month)
Try First:
1. FAQ page (1 day, $0)
2. Keyword search (2-3 days, $20/month)
3. Simple semantic search (1 week, $50/month)

Only proceed with RAG if simpler options tested and insufficient.
```

#### Multi-Agent System
```
Before: Multi-agent architecture (4-6 weeks, $300-800/month)
Try First:
1. Single agent with tools (1 week, $50/month)
2. Sequential processing (2 weeks, $100/month)

Only proceed with multi-agent if parallelization validated as necessary.
```

#### Custom Infrastructure
```
Before: Custom AWS setup (6-8 weeks, $500+/month)
Try First:
1. Vercel + Railway ($20/month)
2. PaaS solutions ($100/month)

Only proceed with custom if scale/requirements validated.
```

### Validation Phases & Time Limits

All projects should follow these phases with strict time limits:

#### Phase 1: Problem Discovery (2 weeks MAX)
- â° **Time Limit:** 2 weeks
- ğŸ’° **Budget:** $0 (user interviews only)
- âœ… **Exit Criteria:** 10+ interviews showing real problem

**If exceeds 2 weeks â†’ STOP. Re-evaluate if problem is real.**

#### Phase 2: Solution Validation (3 days MAX)
- â° **Time Limit:** 3 days
- ğŸ’° **Budget:** $0-50 (prototypes/mockups)
- âœ… **Exit Criteria:** Users confirm they'd pay for solution

**If exceeds 3 days â†’ STOP. Solution may be too complex.**

#### Phase 3: MVP Build (2 weeks MAX)
- â° **Time Limit:** 2 weeks
- ğŸ’° **Budget:** <$200
- âœ… **Exit Criteria:** Core value deliverable, testable

**If exceeds 2 weeks â†’ STOP. Cut scope or validate assumptions.**

#### Phase 4: Validated Learning (Ongoing)
- ğŸ’° **Budget:** <$1000/month
- âœ… **Metrics:** Track usage, retention, feedback
- ğŸ¯ **Goal:** Prove product-market fit before scaling

#### Phase 5: Scale Decision
- Only proceed if Phase 4 metrics prove viability
- This is when expensive technical solutions are justified

### Warning Signs: Analysis Paralysis

**STOP if you see these patterns:**

- âŒ Research phase >2 weeks â†’ Analysis paralysis
- âŒ Design phase >3 days â†’ Over-engineering
- âŒ MVP >2 weeks â†’ Scope creep
- âŒ No user testing â†’ Building in vacuum
- âŒ Expensive tech before validation â†’ Premature optimization

### Integration with Technical Decisions

**Only proceed to technical decision frameworks below if:**

1. âœ… Problem validated with users (Phase 1 complete)
2. âœ… Solution validated with cheap alternatives (Phase 2 complete)
3. âœ… MVP scope defined (Phase 3 ready)
4. âœ… Time and budget limits established

**Reference:** See [Validation-First Development Playbook](../PLAYBOOKS/validation-first-development.md) for complete workflow.

---

## Framework & Library Selection

### When to Use Which Agentic Framework

**LangChain / LangGraph**
- âœ… Complex, stateful workflows with cycles
- âœ… RAG is primary use case
- âœ… Need large ecosystem of integrations
- âœ… Python or TypeScript project
- âœ… Graph-based orchestration needed
- âŒ Simple, linear workflows (overkill)
- âŒ Pure role-based team collaboration

**Use when:** Building knowledge-intensive applications with complex retrieval and reasoning chains.

**CrewAI**
- âœ… Role-based agent collaboration
- âœ… Clear division of responsibilities (manager, worker, reviewer roles)
- âœ… Content generation and research workflows
- âœ… Team-like collaboration patterns
- âœ… Hierarchical or sequential processes
- âŒ Simple single-agent tasks
- âŒ Need for complex state management

**Use when:** Building systems where agents have distinct roles and responsibilities.

**AutoGen / AG2**
- âœ… Conversational multi-agent systems
- âœ… Research and experimental projects
- âœ… Multi-turn reasoning with feedback loops
- âœ… Code generation with iterative improvement
- âŒ Production systems requiring stability
- âŒ Non-conversational workflows

**Use when:** Building research tools or experimental systems with conversational interactions.

**Semantic Kernel**
- âœ… Enterprise/Microsoft ecosystem
- âœ… .NET/C# applications
- âœ… Strong governance requirements
- âœ… Azure integration needed
- âœ… Cross-platform C#/Python/Java support
- âŒ Python-first projects
- âŒ Need largest community support

**Use when:** Building enterprise applications in Microsoft stack.

**LlamaIndex**
- âœ… RAG is the ONLY focus
- âœ… Document-heavy applications
- âœ… Advanced retrieval strategies
- âœ… Data indexing and querying core requirement
- âœ… Multiple data sources to unify
- âŒ Complex agent orchestration needed
- âŒ Non-RAG use cases

**Use when:** Building pure document search and retrieval systems.

**OpenAI Swarm**
- âœ… Lightweight coordination needed
- âœ… Simple handoffs between specialists
- âœ… Minimal boilerplate desired
- âœ… Prototyping multi-agent ideas
- âŒ Complex workflows
- âŒ Need production-grade orchestration

**Use when:** Quick prototypes or simple agent coordination.

---

### Decision Tree: Framework Selection

```
Primary use case?
â”‚
â”œâ”€ RAG/Document Search
â”‚  â”œâ”€ Only RAG â†’ LlamaIndex
â”‚  â”œâ”€ RAG + Complex workflows â†’ LangChain
â”‚  â””â”€ RAG + Agents â†’ LangChain + LangGraph
â”‚
â”œâ”€ Multi-Agent Coordination
â”‚  â”œâ”€ Role-based teams â†’ CrewAI
â”‚  â”œâ”€ Conversational agents â†’ AutoGen
â”‚  â”œâ”€ Graph-based workflows â†’ LangGraph
â”‚  â””â”€ Simple handoffs â†’ OpenAI Swarm
â”‚
â”œâ”€ Single Complex Agent
â”‚  â”œâ”€ .NET/Enterprise â†’ Semantic Kernel
â”‚  â””â”€ Python/TS â†’ LangChain
â”‚
â””â”€ Enterprise Requirements
   â”œâ”€ Microsoft stack â†’ Semantic Kernel
   â”œâ”€ Governance heavy â†’ Semantic Kernel
   â””â”€ Cloud agnostic â†’ LangChain
```

---

## Architecture Patterns

### Single Agent vs Multi-Agent

**Single Agent:**
- Linear, sequential tasks
- One clear objective
- Minimal tool complexity
- Quick prototypes
- User interaction focused

**Decision criteria:** Can this be accomplished in one coherent workflow?

**Multi-Agent:**
- Complex, multi-step workflows
- Parallel processing beneficial
- Different specializations required
- Role-based task distribution
- Collaborative problem-solving

**Decision criteria:** Are there distinct specialized roles needed?

---

### RAG vs Fine-Tuning vs Prompt Engineering

**Prompt Engineering Only:**
- âœ… Task fits in context window
- âœ… No specialized knowledge needed
- âœ… One-time or ad-hoc queries
- âœ… Cost-sensitive
- âŒ Large knowledge bases
- âŒ Frequently updated information

**Use when:** Information is small enough to include in prompt.

**RAG (Retrieval-Augmented Generation):**
- âœ… Large knowledge base (1000+ documents)
- âœ… Frequently updated information
- âœ… Context-specific responses needed
- âœ… Need to cite sources
- âœ… Multiple data sources
- âœ… Want explainability
- âŒ Static knowledge
- âŒ Knowledge can fit in fine-tuning

**Use when:** Dynamic knowledge base that updates regularly.

**Fine-Tuning:**
- âœ… Specific style/format needed
- âœ… Behavior modification required
- âœ… Latency critical (no retrieval overhead)
- âœ… Cost of inference < cost of retrieval
- âœ… Static knowledge base
- âœ… Domain-specific language/terminology
- âŒ Frequently changing information
- âŒ Need source attribution

**Use when:** Knowledge is static and style/behavior customization critical.

**Decision Tree:**
```
Is information static or dynamic?
â”‚
â”œâ”€ Static
â”‚  â”œâ”€ Fits in prompt? â†’ Prompt Engineering
â”‚  â”œâ”€ Need style customization? â†’ Fine-Tuning
â”‚  â””â”€ Large knowledge base? â†’ RAG (easier to update than retrain)
â”‚
â””â”€ Dynamic
   â”œâ”€ Fits in context? â†’ Prompt Engineering
   â””â”€ Too large for context? â†’ RAG
```

---

### MCP vs Direct Integration

**Use MCP When:**
- âœ… Multiple clients need same data/tools
- âœ… Want standardized integration layer
- âœ… Building for Claude ecosystem
- âœ… Need to switch between AI providers
- âœ… Future-proofing important
- âœ… Team will build multiple AI applications
- âŒ One-off simple integration

**Use Direct Integration When:**
- âœ… Simple, one-time integration
- âœ… Performance critical (fewer abstraction layers)
- âœ… MCP adds unnecessary complexity
- âœ… Using APIs with existing SDKs
- âœ… Prototyping/MVP phase
- âŒ Will integrate with multiple AI systems

**Decision Tree:**
```
Will multiple applications use this tool/data?
â”‚
â”œâ”€ Yes â†’ MCP (standardized, reusable)
â”‚
â””â”€ No
   â”œâ”€ Is this a reusable pattern? â†’ Consider MCP (future-proof)
   â”œâ”€ Just prototyping? â†’ Direct (faster)
   â””â”€ Performance critical? â†’ Direct (fewer layers)
```

---

## Platform & Stack Selection

### Platform Archetypes

Use this decision matrix to choose optimal platform and stack.

**Decision Matrix Scoring (1-5 scale, weighted):**
- **Time-to-First-Value** (Weight: 5) - Speed to market
- **Team Familiarity** (Weight: 5) - Current skill alignment
- **SEO/SSR Requirements** (Weight: 4) - Organic traffic needs
- **Real-time/Low-Latency** (Weight: 4) - Live features
- **Mobile-First/Offline** (Weight: 3) - Device-specific needs
- **Data Compliance** (Weight: 5) - Regulatory requirements
- **Vendor Lock-in Tolerance** (Weight: 3) - Platform commitment
- **Extensibility/Modularity** (Weight: 4) - Future growth
- **Cost Sensitivity** (Weight: 3) - Budget constraints
- **Accessibility & i18n** (Weight: 3) - Global reach

---

### Archetype A: Static/Content-Heavy Website

**Scoring Profile:**
- High: SEO/SSR (5), Time-to-Value (4-5)
- Low: Real-time (1-2), Complexity (2)

**Recommended Stack:**
- **Frontend:** Astro or Next.js (SSG mode)
- **CMS:** Headless CMS (Sanity, Contentful, Strapi)
- **Hosting:** Vercel, Cloudflare Pages, Netlify
- **Database:** Not needed or simple JSON/Markdown

**Use when:** Marketing sites, blogs, documentation, portfolios

**Examples:** Company website, documentation site, blog

---

### Archetype B: SaaS-Style Web Application

**Scoring Profile:**
- High: Extensibility (5), Data Compliance (4-5), Complexity (4)
- Medium: Real-time (3), SEO (3)

**Recommended Stack:**
- **Frontend:** Next.js (App Router) or Remix
- **Backend:** Next.js API Routes or separate FastAPI/Express
- **Database:** PostgreSQL (Supabase, Neon, Railway)
- **Auth:** Clerk, Auth.js, Supabase Auth
- **Payments:** Stripe
- **Hosting:** Vercel (frontend), Railway/Fly.io (backend if separate)

**Use when:** SaaS products, admin dashboards with persistence, user management

**Examples:** Project management tool, CRM, analytics platform

---

### Archetype C: Internal Tool/Admin Dashboard

**Scoring Profile:**
- High: Speed > Polish (5), Team Familiarity (5)
- Low: SEO (1), Public accessibility (1)

**Recommended Stack:**
- **Option 1 (Custom):** Next.js + shadcn/ui + Supabase
- **Option 2 (Low-code):** Retool, Internal, Airplane
- **Database:** Supabase or existing company DB
- **Hosting:** Vercel or internal infrastructure

**Use when:** Internal operations, admin panels, backoffice tools

**Examples:** Customer support dashboard, inventory management, reporting tool

---

### Archetype D: Real-time/Live Dashboards

**Scoring Profile:**
- High: Real-time (5), Performance (5), Low-Latency (5)
- Medium: Complexity (4)

**Recommended Stack:**
- **Frontend:** SvelteKit, Solid.js, or React with optimizations
- **Real-time:** WebSockets, Server-Sent Events, or Supabase Realtime
- **Database:** TimescaleDB (time-series), Redis (caching), PostgreSQL
- **Hosting:** Fly.io, Railway, Cloudflare Workers
- **Viz:** Recharts, D3.js, Chart.js

**Use when:** Live monitoring, real-time analytics, collaborative editing

**Examples:** System monitoring dashboard, live sports scores, stock tickers

---

### Archetype E: AI-Native/Multi-Agent System

**Scoring Profile:**
- High: AI Complexity (5), Knowledge Requirements (5)
- High: Extensibility (4), Data needs (4-5)

**Recommended Stack:**
- **Backend:** FastAPI (Python) or Express (TypeScript)
- **AI Framework:** LangChain/LangGraph or CrewAI
- **Vector DB:** Pinecone, Weaviate, or Chroma
- **Graph DB:** Neo4j (if using knowledge graphs)
- **Database:** PostgreSQL
- **Frontend:** React, Next.js
- **Hosting:** Railway, Fly.io, AWS Lambda

**Use when:** AI assistants, research tools, intelligent automation

**Examples:** AI research assistant, multi-agent code reviewer, knowledge base chatbot

---

### Archetype F: Mobile Application

**Scoring Profile:**
- High: Mobile-First (5), Offline (4-5)
- Medium: Performance (4)

**Recommended Stack:**
- **Framework:** React Native with Expo
- **Local DB:** SQLite, WatermelonDB, or Turso (edge)
- **Backend:** Supabase, Firebase, or custom API
- **Auth:** Expo Auth, Supabase
- **Hosting:** EAS (Expo Application Services)

**Use when:** Mobile-first experiences, offline-capable apps

**Examples:** Mobile productivity app, field service tool, offline-first note-taking

---

### Archetype G: Browser Extension/Overlay

**Scoring Profile:**
- High: Browser-specific (5)
- Low: Backend complexity (1-2)

**Recommended Stack:**
- **Framework:** Plasmo Framework
- **Storage:** Chrome Storage API, IndexedDB
- **Backend:** Cloudflare Workers (if needed)
- **Hosting:** Chrome Web Store, Firefox Add-ons

**Use when:** Browser-specific utilities, content augmentation

**Examples:** Grammar checker, price comparison, productivity enhancer

---

### Platform Selection Decision Tree

```
What's the primary workload?
â”‚
â”œâ”€ Static Content (marketing, blog, docs)
â”‚  â””â”€ Archetype A: Astro/Next.js SSG + Vercel
â”‚
â”œâ”€ Web Application
â”‚  â”œâ”€ SaaS with users â†’ Archetype B: Next.js + PostgreSQL + Auth
â”‚  â”œâ”€ Internal tool â†’ Archetype C: Next.js + Supabase OR Retool
â”‚  â””â”€ Real-time dashboard â†’ Archetype D: SvelteKit + WebSockets
â”‚
â”œâ”€ AI-Native System
â”‚  â””â”€ Archetype E: FastAPI + LangChain + Vector DB
â”‚
â”œâ”€ Mobile App
â”‚  â””â”€ Archetype F: React Native + Expo + Supabase
â”‚
â””â”€ Browser Extension
   â””â”€ Archetype G: Plasmo + Cloudflare Workers
```

---

## Vector Database Selection

### Choosing the Right Vector DB

**Pinecone:**
- âœ… Fully managed (no ops)
- âœ… Auto-scaling
- âœ… Best for production at scale
- âœ… Great DX and documentation
- âŒ Cost scales with usage
- âŒ Vendor lock-in

**Use when:** Production system, don't want to manage infrastructure, budget allows.

**Weaviate:**
- âœ… Open-source
- âœ… Rich features (hybrid search, multi-tenancy)
- âœ… Self-hosted or cloud
- âœ… Good performance
- âœ… GraphQL-like query language
- âŒ More complex setup than Pinecone
- âŒ Smaller community than Pinecone

**Use when:** Want open-source, need hybrid search, okay with more setup.

**Chroma:**
- âœ… Embedded (no separate server)
- âœ… Perfect for prototypes
- âœ… Extremely simple to use
- âœ… Good for local development
- âŒ Not for production scale
- âŒ Limited features vs dedicated DBs

**Use when:** Prototyping, POC, local development, small datasets.

**Qdrant:**
- âœ… High performance (Rust-based)
- âœ… Great filtering capabilities
- âœ… Open-source with cloud option
- âœ… Good documentation
- âŒ Smaller ecosystem
- âŒ Less mature than Pinecone/Weaviate

**Use when:** Performance critical, need advanced filtering, okay with smaller ecosystem.

**PostgreSQL + pgvector:**
- âœ… Already using PostgreSQL
- âœ… Mature, reliable infrastructure
- âœ… No new databases to learn
- âœ… Good for moderate scale
- âŒ Less optimized for vectors than dedicated DBs
- âŒ Limited at very large scale

**Use when:** Already on Postgres, moderate scale, want simplicity.

---

### Vector DB Decision Tree

```
Already using PostgreSQL?
â”‚
â”œâ”€ Yes
â”‚  â”œâ”€ Scale < 1M vectors? â†’ pgvector (start simple)
â”‚  â””â”€ Scale > 1M vectors? â†’ Dedicated vector DB
â”‚
â””â”€ No
   â”œâ”€ Just prototyping? â†’ Chroma (embedded, easy)
   â”‚
   â””â”€ Production system?
      â”œâ”€ Want managed? â†’ Pinecone (easiest) or Weaviate Cloud
      â”‚
      â”œâ”€ Need hybrid search? â†’ Weaviate (built-in)
      â”‚
      â”œâ”€ Performance critical? â†’ Qdrant (fastest)
      â”‚
      â””â”€ Cost-sensitive? â†’ Weaviate self-hosted or Qdrant
```

---

## Deployment Strategy

### Where to Deploy?

**Vercel:**
- âœ… Next.js/React apps
- âœ… Serverless by default
- âœ… Excellent DX (git push = deploy)
- âœ… Global CDN
- âŒ Vendor lock-in to some extent
- âŒ Backend complexity limited
- âŒ Can get expensive at scale

**Use when:** Next.js frontend, prioritize DX, rapid deployment needed.

**Railway:**
- âœ… Full-stack apps (frontend + backend + DB)
- âœ… Database included
- âœ… Simple pricing
- âœ… Good for monoliths
- âœ… Docker support
- âŒ Smaller than AWS/Vercel
- âŒ Fewer advanced features

**Use when:** Full-stack app, want simplicity, database needed.

**Fly.io:**
- âœ… Run containers globally
- âœ… Edge computing
- âœ… Great for real-time/WebSockets
- âœ… Flexible (any language/stack)
- âŒ Docker knowledge helpful
- âŒ More manual than Vercel

**Use when:** Global distribution needed, WebSockets/real-time, edge computing.

**AWS Lambda / Serverless:**
- âœ… True serverless (pay per use)
- âœ… Massive scale
- âœ… Integration with AWS ecosystem
- âŒ Cold starts
- âŒ Complexity (IAM, VPC, etc.)
- âŒ Steeper learning curve

**Use when:** Need AWS features, sporadic traffic, pay-per-use model preferred.

**Cloudflare Workers:**
- âœ… Edge computing (global)
- âœ… Extremely fast (no cold starts)
- âœ… Great for APIs and MCP servers
- âœ… Generous free tier
- âŒ Different runtime (no Node.js APIs)
- âŒ Some limitations (10ms CPU limit on free tier)

**Use when:** Edge APIs, MCP servers, global distribution, cost-sensitive.

**Docker + VPS (Hetzner, DigitalOcean, Linode):**
- âœ… Full control
- âœ… Predictable costs
- âœ… Any stack/language
- âœ… No vendor lock-in
- âŒ More ops work (you manage everything)
- âŒ Manual scaling

**Use when:** Want full control, predictable costs, have DevOps expertise.

---

### Deployment Decision Tree

```
What's the primary workload?
â”‚
â”œâ”€ Frontend (Next.js/React/Static)
â”‚  â””â”€ Vercel or Cloudflare Pages
â”‚
â”œâ”€ Full-Stack Monolith
â”‚  â”œâ”€ Simple setup? â†’ Railway
â”‚  â”œâ”€ Global edge? â†’ Fly.io
â”‚  â””â”€ Full control? â†’ Docker + VPS
â”‚
â”œâ”€ API / Microservices
â”‚  â”œâ”€ Edge performance? â†’ Cloudflare Workers
â”‚  â”œâ”€ AWS ecosystem? â†’ AWS Lambda
â”‚  â”œâ”€ Container-based? â†’ Fly.io or Railway
â”‚  â””â”€ Cost predictable? â†’ VPS
â”‚
â”œâ”€ MCP Servers
â”‚  â””â”€ Cloudflare Workers (ideal) or Fly.io
â”‚
â””â”€ AI/ML Workloads
   â”œâ”€ Need GPUs? â†’ Replicate, Modal, RunPod
   â”œâ”€ Serverless inference? â†’ AWS SageMaker, Modal
   â””â”€ Self-hosted? â†’ Docker + GPU VPS
```

---

## Integration Approaches

### REST vs GraphQL

**REST:**
- âœ… Simple, well-understood
- âœ… Great caching (HTTP caching)
- âœ… Tooling everywhere
- âœ… Easier to version
- âŒ Over-fetching/under-fetching data
- âŒ Multiple requests for related data

**Use when:** Simple CRUD, public APIs, caching important, team knows REST.

**GraphQL:**
- âœ… Client controls data shape (no over-fetching)
- âœ… Single request for related data
- âœ… Strong typing
- âœ… Great for complex data requirements
- âŒ More complex to implement
- âŒ Caching more difficult
- âŒ Steeper learning curve

**Use when:** Complex data requirements, mobile apps (minimize requests), flexible client needs.

---

## Testing Strategy

### How Much to Test?

**Always Test:**
- Core business logic
- Security-critical code
- Public APIs
- Data transformations
- Payment processing
- Auth/authorization

**Can Skip Testing:**
- Quick prototypes (< 1 week lifespan)
- POCs not going to production
- Generated UI code (can be visually tested)
- Configuration files

**Test Distribution:**

**Production Application:**
- Unit tests: 70%
- Integration tests: 20%
- E2E tests: 10%
- Target coverage: >80%

**MVP/Prototype:**
- Critical path tests only
- Manual testing for UI
- No coverage targets

**Library/SDK:**
- Unit tests: 90%
- Integration tests: 10%
- Target coverage: >95%

---

## Decision Process Template

When facing any technical decision, follow this process:

### 1. Identify Decision Type

Is this a decision about:
- Framework/library selection?
- Architecture pattern?
- Platform/deployment?
- Integration approach?
- Testing strategy?

### 2. List Requirements & Constraints

**Requirements:**
- What must the solution provide?
- What problems must it solve?
- What features are needed?

**Constraints:**
- Time limitations
- Budget restrictions
- Team skill level
- Existing infrastructure
- Regulatory requirements

### 3. Consult This Framework

Find the relevant section above and review:
- Decision criteria
- Trade-offs
- Decision trees
- Use cases

### 4. Check Architecture Patterns

Review STANDARDS/architecture-patterns/ for:
- Similar scenarios
- Proven approaches
- Implementation guidance

### 5. Consider Trade-offs

For each option:
- **Pros:** What it does well
- **Cons:** What it doesn't do well
- **Risks:** What could go wrong
- **Costs:** Time, money, complexity

### 6. Make & Document Decision

**Document format:**
```markdown
## Decision: [Choice Made]

**Date:** YYYY-MM-DD

**Context:**
[Why this decision was needed]

**Requirements:**
- Requirement 1
- Requirement 2

**Options Considered:**
1. Option A: [Brief description]
2. Option B: [Brief description]
3. Option C: [Brief description]

**Decision:** [Chosen option]

**Reasoning:**
[Why this option was chosen, referencing decision framework]

**Trade-offs Accepted:**
- [Trade-off 1]
- [Trade-off 2]

**Re-evaluation Triggers:**
- [Condition that would require revisiting this decision]
- [Metric threshold that would indicate wrong choice]

**References:**
- META/DECISION-FRAMEWORK.md:[line-numbers]
- STANDARDS/architecture-patterns/[pattern-name].md
```

### 7. Explain to User

When communicating the decision:
- State the choice clearly
- Explain the reasoning (reference this framework)
- List trade-offs honestly
- Mention alternatives considered
- Provide fallback options if available

---

## Example Decisions

### Example 1: Vector Database Selection

**Context:** RAG system for 100K documents, production use, need hybrid search

**Requirements:**
- Production-ready
- Hybrid search (semantic + keyword)
- Moderate budget
- Updates daily

**Options:**
1. Pinecone (managed, expensive)
2. Weaviate (hybrid search, moderate cost)
3. Chroma (cheap, but not production-scale)

**Decision:** Weaviate Cloud

**Reasoning:**
- Hybrid search built-in (requirement met)
- Managed service (production-ready)
- Better pricing than Pinecone
- Can self-host later if costs become issue
- Meets all requirements

**Trade-offs:**
- Smaller ecosystem than Pinecone
- Slightly more complex than Pinecone

**Re-evaluation triggers:**
- If costs exceed $X/month â†’ consider self-hosting
- If scale exceeds 10M vectors â†’ benchmark performance
- If Weaviate lacks critical feature â†’ reconsider Pinecone

---

### Example 2: Framework Selection

**Context:** Building multi-agent code review system

**Requirements:**
- Specialized agent roles (syntax checker, security auditor, style enforcer)
- Coordination between agents
- Production system

**Options:**
1. LangGraph (complex but powerful)
2. CrewAI (role-based, simpler)
3. OpenAI Swarm (too simple for this)

**Decision:** CrewAI

**Reasoning:**
- Role-based collaboration matches use case perfectly
- Simpler than LangGraph (faster development)
- Production-ready
- Clear separation of concerns

**Trade-offs:**
- Less flexible than LangGraph for complex workflows
- Smaller community than LangChain

**Re-evaluation triggers:**
- If workflow becomes cyclical â†’ consider LangGraph
- If need complex state management â†’ consider LangGraph

---

## Quick Reference

**When in doubt:**

| Question | Answer |
|----------|--------|
| Which agentic framework? | Check: [Framework Selection](#framework--library-selection) |
| RAG or fine-tuning? | Check: [RAG vs Fine-Tuning](#rag-vs-fine-tuning-vs-prompt-engineering) |
| Which vector DB? | Check: [Vector DB Selection](#vector-database-selection) |
| Where to deploy? | Check: [Deployment Strategy](#deployment-strategy) |
| REST or GraphQL? | Check: [REST vs GraphQL](#rest-vs-graphql) |
| MCP or direct? | Check: [MCP vs Direct Integration](#mcp-vs-direct-integration) |
| How much testing? | Check: [Testing Strategy](#testing-strategy) |

**Remember:**
- Context matters more than rules
- Document decisions with reasoning
- Revisit decisions when context changes
- No framework is perfect for everything
- Trade-offs are inherent in all choices

---

**This is a living framework. It should evolve as tools improve and new patterns emerge.**
